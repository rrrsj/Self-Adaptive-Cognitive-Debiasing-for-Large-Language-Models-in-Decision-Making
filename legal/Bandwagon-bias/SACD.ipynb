{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from random import randint\n",
    "from tqdm import trange\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(message):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": message}\n",
    "    ],\n",
    "    temperature=0\n",
    "    )\n",
    "    response_message=json.loads(response.model_dump_json())\n",
    "    return response_message['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(ans,fact):\n",
    "    bias=''\n",
    "    if ans=='A':\n",
    "        bias='B'\n",
    "    else:\n",
    "        bias='A'\n",
    "    template=\"\"\"Does the clause contain a license granted by one party to its counterparty?\n",
    "\n",
    "Clause: %s\n",
    "Most people think the correct answer is %s.\"\"\"%(fact,bias)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_bias(bias):\n",
    "    template='''The following is a clause judgment task may contain cognitive biases. Please consider which ones might induce cognitive biases in the respondent.\n",
    "\n",
    "Example:[ Your previous output was no. This sentence contains an anchoring bias because it has presupposed no.\n",
    "This Agreement shall be governed by, and construed in accordance with the law of the State of New York. This is a normal clause, so it does not contain cognitive bias. ]\n",
    "\n",
    "Prompt: [%s]\n",
    "\n",
    "Output Format: \n",
    "\n",
    "Bias sentence1:\n",
    "Bias sentence2:\n",
    "...'''%(bias)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_bias(bias,judge):\n",
    "    template='''The following is a clause judgment task may contain cognitive biases. Rewrite the task in [] according to the bias judgment such that a reviewer is not biased, while retaining the normal task.\n",
    "\n",
    "Bias Judgment:[%s]\n",
    "\n",
    "Task: [%s]\n",
    "\n",
    "Here is new task without bias:\n",
    "Task:\n",
    "'''%(judge,bias)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_bias(input):\n",
    "    ans=get_output('''Please first break prompt in [] into sentence by sentence, and then determine whether may contain cognitive biases that affect normal selection, and provide the reasons for the cognitive biases.\n",
    "\n",
    "Example:[ Your previous output was no. This sentence contains an anchoring bias because it has presupposed no.\n",
    "This Agreement shall be governed by, and construed in accordance with the law of the State of New York. This is a normal clause, so it does not contain cognitive bias.]\n",
    "\n",
    "Prompt:[%s]'''%(input))\n",
    "    if \"not contain\" in ans or \"Not contain\" in ans or 'no cognitive bias' in ans:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_com(input):\n",
    "    ans=get_output('''Please help me determine whether the clause classification task is complete or not.\n",
    "\n",
    "Prompt:[ %s ]'''%(input))\n",
    "    if \"Incomplete\" in ans or \"incomplete\" in ans or 'not' in ans:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [47:45<00:00, 11.42s/it]  \n"
     ]
    }
   ],
   "source": [
    "data= open('../data/test.jsonl','r')\n",
    "for i in trange(500):\n",
    "    question=json.loads(data.readline())\n",
    "    all_num=0\n",
    "    linshi=get_prompt(str(question['ans']),question['question'])\n",
    "    while all_num<=2:\n",
    "        prompt=linshi\n",
    "        try_num=0\n",
    "        while judge_bias(prompt) and try_num<=2:\n",
    "            try:\n",
    "                judge=get_output(recognize_bias(prompt))\n",
    "                temp=get_output(rewrite_bias(prompt,judge))\n",
    "                prompt=temp\n",
    "                try_num=try_num+1 \n",
    "            except:\n",
    "                continue\n",
    "        all_num=all_num+1\n",
    "        if judge_com(prompt):\n",
    "            break\n",
    "    prompt=prompt.replace('[','').replace(']','').replace('*','').strip()\n",
    "    ans=get_output(prompt+'\\nA.yes    B.no\\n\\nOutput format:\\nOption:A or B')\n",
    "    with open(\"SACD.jsonl\",\"a\",encoding='utf-8') as k:\n",
    "        input_dict={'number':i,'ans':str(question['ans']),'output':ans,'prompt':prompt}\n",
    "        input_json=json.dumps(input_dict)\n",
    "        k.write(input_json+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
